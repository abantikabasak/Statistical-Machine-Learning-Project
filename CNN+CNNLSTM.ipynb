{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Abantika_Mel_Spectrogram_CNN_modified.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c9p8raqyvmqL",
        "outputId": "05453d52-ff5b-4d04-d39a-ce966579d1c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import random\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "tf.test.gpu_device_name()\n",
        "\n",
        "\n",
        "import os\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38EFdBgb0VMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getcategories(categories,list_of_files,path):\n",
        "    for files in os.listdir(path):\n",
        "        if \".mf\" not in files:\n",
        "            categories.append(files)\n",
        "            list_of_files[files] = list()\n",
        "            newPath = os.path.join(path,files)\n",
        "            for f in os.listdir(newPath):\n",
        "                list_of_files[files].append(f)\n",
        "    #print(list_of_files)\n",
        "    return(categories,list_of_files)\n",
        "train_directory = '/content/gdrive/My Drive/train1'\n",
        "categories=[]    \n",
        "list_of_files = {} # a dictionary with the genre as the key value. For every key value, we have a list which contains the names of the audio files contained within that genre folder\n",
        "categories,list_of_files = getcategories(categories,list_of_files,train_directory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e_XRDxl44WE2",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "def get_index(category,categories):\n",
        "    print(category)\n",
        "    for i in range(0,len(categories)):\n",
        "        if(categories[i]==category):\n",
        "            break\n",
        "    return(i)\n",
        "\n",
        "def genTrainTest(training_data,test_data,list_of_files,categories,directory):\n",
        "    list1 = [x for x in range(100)] #Since we have 100 files in each genre, I take a list which contains values like [0,1,2,3,4,.....,100].\n",
        "    list2 = list1 #create a backup of list1\n",
        "    for category in list_of_files.keys(): #For each music genre\n",
        "        category1 = category + \"/\"\n",
        "        path = os.path.join(directory,category1) #helps to navigate through the required genre directory\n",
        "        #print(path)\n",
        "        class_label = get_index(category,categories) #we have to represent each category by a number which is nothing but the position of the genre name in the categories list. \n",
        "        test_index=[]\n",
        "        for direc,_,filenames in os.walk(path):\n",
        "              #print(\"Length of filenames\"+str(len(filenames)))\n",
        "             # print(filenames)\n",
        "              random.shuffle(list1) #shuffling the list \n",
        "              train_index = list1[:90] #take the first 70 random indices as train indices\n",
        "              #print(\"List1: \"+str(list1))\n",
        "              #print(\"Training index: \"+str(train_index))\n",
        "              #print(len(train_index))\n",
        "              #count=0\n",
        "              #count1 = 0\n",
        "              #count2=0\n",
        "              #print(len(list1))\n",
        "              for i in range(0,len(list1)):\n",
        "                if(list1[i] not in train_index):\n",
        "                    test_index.append(list1[i]) #remaining 30 for test indices\n",
        "              #print(count,count1,count2)\n",
        "              #print(train1_index==train_index)\n",
        "              #test_index = list(set(list1)-set(train_index))\n",
        "              #print(len(test_index))\n",
        "              #print(\"Test index: \"+str(test_index))\n",
        "\n",
        "\n",
        "              for i in train_index:\n",
        "                    full_path=os.path.join(path,filenames[i]) #navigate to each genre subfolder\n",
        "                    img_arr = cv2.imread(full_path) #Read the image\n",
        "                    #print(img_arr)\n",
        "                    im_rgb = cv2.cvtColor(img_arr,cv2.COLOR_BGR2RGB) #Convert into RGB as colour is important\n",
        "                    #print(im_rgb.shape)\n",
        "\n",
        "\n",
        "                    #plt.imshow(im_rgb)\n",
        "                    #plt.show()\n",
        "                    training_data.append([im_rgb,class_label]) #each row in the training data contains the rgb numpy matrix and the class label \n",
        "\n",
        "\n",
        "\n",
        "              for i in test_index:\n",
        "                    full_path=os.path.join(path,filenames[i])\n",
        "                    img_arr = cv2.imread(full_path)\n",
        "                    #print(img_arr.shape)\n",
        "                    im_rgb = cv2.cvtColor(img_arr,cv2.COLOR_BGR2RGB)\n",
        "                    #print(im_rgb.shape)\n",
        "                    #plt.imshow(im_rgb)\n",
        "                    #plt.show()\n",
        "                    test_data.append([im_rgb,class_label]) #similarly for test data\n",
        "                    \n",
        "                    \n",
        "    return training_data,test_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IVzbpfFt4-LO",
        "colab": {}
      },
      "source": [
        "def convert_to_numpy(training_data,test_data):\n",
        "    X=[]\n",
        "    Y=[]\n",
        "    for features,class_label in training_data:\n",
        "        X.append(features)\n",
        "        Y.append(class_label)\n",
        "        \n",
        "    #X has to be a numpy array\n",
        "    Y=np.array(Y)\n",
        "    #X=np.asarray(X)\n",
        "    #print(len(X[0]))\n",
        "    #print(len(X[0][0]))\n",
        "    #print(len(X[0][0][0]))\n",
        "    #X=np.array(X)\n",
        "    X=np.array(X)\n",
        "    #print(X.shape)\n",
        "    #print(Y.shape)\n",
        "    np.save(\"X.npy\",X)\n",
        "    np.save(\"Y.npy\",Y)\n",
        "\n",
        "\n",
        "    X2 = []\n",
        "    Y2 = []\n",
        "    for features, class_label in test_data:\n",
        "        X2.append(features)\n",
        "        Y2.append(class_label)\n",
        "    X2 = np.array(X2)\n",
        "    Y2 = np.array(Y2)\n",
        "    np.save(\"X2.npy\",X2)\n",
        "    np.save(\"Y2.npy\",Y2)\n",
        "\n",
        "\n",
        "    return(X,Y,X2,Y2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gBHs33zV6SGS",
        "outputId": "98a98e15-f386-4c06-ad76-12276d967bed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UQRT_Nq05DuQ",
        "outputId": "e9c51f2f-ffa4-4e7d-ad45-40d265962fbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "\n",
        "\n",
        "training_data=[]\n",
        "test_data=[]\n",
        "training_data, test_data = genTrainTest(training_data,test_data,list_of_files,categories,train_directory)\n",
        "print(len(training_data))\n",
        "print(len(test_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "metal\n",
            "country\n",
            "pop\n",
            "blues\n",
            "reggae\n",
            "jazz\n",
            "disco\n",
            "hiphop\n",
            "rock\n",
            "classical\n",
            "900\n",
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AK85S8lu5OPu",
        "outputId": "bc94b0ca-e4c4-4326-c041-d313a9297b83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential,Model\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, LSTM,Conv2D, Dropout,Input, Flatten,Activation,MaxPooling2D,AveragePooling2D,BatchNormalization,Conv3D\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "def convert_to_numpy(training_data,test_data):\n",
        "    X=[]\n",
        "    Y=[]\n",
        "    for features,class_label in training_data:\n",
        "        X.append(features)\n",
        "        Y.append(class_label)\n",
        "        \n",
        "    #X has to be a numpy array\n",
        "    Y=np.array(Y)\n",
        "    #X=np.asarray(X)\n",
        "    #print(len(X[0]))\n",
        "    #print(len(X[0][0]))\n",
        "    #print(len(X[0][0][0]))\n",
        "    #X=np.array(X)\n",
        "    X=np.array(X)\n",
        "    #print(X.shape)\n",
        "    #print(Y.shape)\n",
        "    np.save(\"X.npy\",X)\n",
        "    np.save(\"Y.npy\",Y)\n",
        "\n",
        "\n",
        "    X2 = []\n",
        "    Y2 = []\n",
        "    for features, class_label in test_data:\n",
        "        X2.append(features)\n",
        "        Y2.append(class_label)\n",
        "    X2 = np.array(X2)\n",
        "    Y2 = np.array(Y2)\n",
        "    np.save(\"X2.npy\",X2)\n",
        "    np.save(\"Y2.npy\",Y2)\n",
        "\n",
        "\n",
        "    return(X,Y,X2,Y2)\n",
        "\n",
        "\n",
        "\n",
        "def train_model():\n",
        "\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32,(3,3),padding='same',activation='relu',input_shape=(480,640,3)))\n",
        "    model.add(Conv2D(32,(3,3),activation='relu'))\n",
        "    model.add(AveragePooling2D(pool_size = (2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64,(4,4),padding='same',activation='relu',strides=(2,2)))\n",
        "    model.add(Conv2D(64,(4,4),activation='relu',strides=(2,2)))\n",
        "    model.add(AveragePooling2D(pool_size = (2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64,(4,4),padding='same',activation='relu'))\n",
        "    model.add(Conv2D(64,(4,4),activation='relu'))\n",
        "    model.add(AveragePooling2D(pool_size = (2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    #model.add(Conv2D(64,(10,10),padding='same',activation='relu',strides=(2,2)))\n",
        "    #model.add(Conv2D(64,(10,10),activation='relu',strides=(2,2)))\n",
        "    #model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "    #model.add(Dropout(0.25))\n",
        "\n",
        "    #LSTM\n",
        "\n",
        "\n",
        "    #model.add(LSTM(96,input_shape=(7,704)))\n",
        "    \"\"\"\n",
        "    lstm1,h,c = LSTM(96, return_sequences=True,return_state=True)([lstm1,h,c])\n",
        "    lstm1,h,c = LSTM(96, return_sequences=False,return_state=True)([lstm1,h,c])\n",
        "    #y = Lambda(lambda x: tf.keras.backend.concatenate([h,c],0))([lstm1,h,c])\n",
        "    y = Concatenate()([h,c])\n",
        "    model_language = Model(inputs=inputs1, outputs=y)\n",
        "    # combined model\n",
        "    conc = keras.layers.Multiply()([model_language.output,model.output])\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1000,activation='relu'))\n",
        "    #model.add(Dropout(0.2))\n",
        "    model.add(Dense(512,activation='relu'))\n",
        "    #model.add(Dropout(0.2))\n",
        "    model.add(Dense(64,activation='relu'))\n",
        "\n",
        "    model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "    model.summary()\n",
        "    return(model)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X,Y,X2,Y2 = convert_to_numpy(training_data,test_data) #since training_data and test_data are lists, we need to convert them into numpy arrays for further processing.\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "print(X2.shape)\n",
        "print(Y2.shape)\n",
        "\n",
        "X = X.astype('float32') #Convert all the pixel values to float type as we are going to normalise them for training features\n",
        "X2 = X2.astype('float32') #Convert all the pixel values to float type as we are going to normalise them for test features\n",
        "X/=255 #Normalising the training features\n",
        "X2/=255 #Normalising the test features\n",
        "\n",
        "Y1=to_categorical(Y,10) #use one-hot encoding for training class labels (required for cnn)\n",
        "Y3 = to_categorical(Y2,10) #use one-hot encoding for test class labels (required for cnn)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(900, 480, 640, 3)\n",
            "(900,)\n",
            "(100, 480, 640, 3)\n",
            "(100,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-LdFyKgWmf5q",
        "outputId": "ca80cb17-81e6-498c-ea96-e18e011c4f07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n",
        "model = train_model()\n",
        "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "checkpointer = ModelCheckpoint(filepath='/content/gdrive/My Drive/CNNModel1.h5',monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "history = model.fit(X,Y1,batch_size =32 ,epochs=100,verbose=1,validation_data=(X2,Y3),callbacks=[checkpointer])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_61 (Conv2D)           (None, 480, 640, 32)      896       \n",
            "_________________________________________________________________\n",
            "conv2d_62 (Conv2D)           (None, 478, 638, 32)      9248      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_31 (Averag (None, 239, 319, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 239, 319, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_63 (Conv2D)           (None, 120, 160, 64)      32832     \n",
            "_________________________________________________________________\n",
            "conv2d_64 (Conv2D)           (None, 59, 79, 64)        65600     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_32 (Averag (None, 29, 39, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 29, 39, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_65 (Conv2D)           (None, 29, 39, 64)        65600     \n",
            "_________________________________________________________________\n",
            "conv2d_66 (Conv2D)           (None, 26, 36, 64)        65600     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_33 (Averag (None, 13, 18, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 13, 18, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 14976)             0         \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 1000)              14977000  \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 512)               512512    \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 15,762,770\n",
            "Trainable params: 15,762,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 900 samples, validate on 100 samples\n",
            "Epoch 1/100\n",
            "900/900 [==============================] - 11s 12ms/step - loss: 2.4799 - acc: 0.0878 - val_loss: 2.3026 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.10000, saving model to /content/gdrive/My Drive/CNNModel1.h5\n",
            "Epoch 2/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 2.3034 - acc: 0.0878 - val_loss: 2.3026 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.10000\n",
            "Epoch 3/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 2.3031 - acc: 0.0956 - val_loss: 2.3026 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.10000\n",
            "Epoch 4/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 2.3030 - acc: 0.0811 - val_loss: 2.3026 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.10000\n",
            "Epoch 5/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 2.3030 - acc: 0.0856 - val_loss: 2.3026 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.10000\n",
            "Epoch 6/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 2.4599 - acc: 0.0867 - val_loss: 2.3027 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.10000\n",
            "Epoch 7/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 2.3033 - acc: 0.0933 - val_loss: 2.3027 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.10000\n",
            "Epoch 8/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 2.3031 - acc: 0.0911 - val_loss: 2.3026 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.10000\n",
            "Epoch 9/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 2.3034 - acc: 0.0989 - val_loss: 2.3026 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.10000\n",
            "Epoch 10/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 2.3298 - acc: 0.0878 - val_loss: 2.3026 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.10000\n",
            "Epoch 11/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 2.3353 - acc: 0.1156 - val_loss: 2.2945 - val_acc: 0.0700\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.10000\n",
            "Epoch 12/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 2.2594 - acc: 0.1456 - val_loss: 3.0323 - val_acc: 0.1100\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.10000 to 0.11000, saving model to /content/gdrive/My Drive/CNNModel1.h5\n",
            "Epoch 13/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 2.1213 - acc: 0.1889 - val_loss: 2.1316 - val_acc: 0.1500\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.11000 to 0.15000, saving model to /content/gdrive/My Drive/CNNModel1.h5\n",
            "Epoch 14/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 2.0649 - acc: 0.2322 - val_loss: 2.1313 - val_acc: 0.2100\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.15000 to 0.21000, saving model to /content/gdrive/My Drive/CNNModel1.h5\n",
            "Epoch 15/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 1.9648 - acc: 0.2733 - val_loss: 1.9333 - val_acc: 0.2900\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.21000 to 0.29000, saving model to /content/gdrive/My Drive/CNNModel1.h5\n",
            "Epoch 16/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 1.8792 - acc: 0.2911 - val_loss: 1.9596 - val_acc: 0.2600\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.29000\n",
            "Epoch 17/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 1.8208 - acc: 0.3022 - val_loss: 1.9558 - val_acc: 0.3800\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.29000 to 0.38000, saving model to /content/gdrive/My Drive/CNNModel1.h5\n",
            "Epoch 18/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 1.7619 - acc: 0.3533 - val_loss: 2.1705 - val_acc: 0.2900\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.38000\n",
            "Epoch 19/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 1.6672 - acc: 0.4244 - val_loss: 2.0561 - val_acc: 0.4200\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.38000 to 0.42000, saving model to /content/gdrive/My Drive/CNNModel1.h5\n",
            "Epoch 20/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 1.5917 - acc: 0.4089 - val_loss: 1.7375 - val_acc: 0.4500\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.42000 to 0.45000, saving model to /content/gdrive/My Drive/CNNModel1.h5\n",
            "Epoch 21/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 1.4398 - acc: 0.4767 - val_loss: 1.5167 - val_acc: 0.4500\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.45000\n",
            "Epoch 22/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 1.2949 - acc: 0.5400 - val_loss: 1.4262 - val_acc: 0.4800\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.45000 to 0.48000, saving model to /content/gdrive/My Drive/CNNModel1.h5\n",
            "Epoch 23/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 1.2170 - acc: 0.5644 - val_loss: 1.9816 - val_acc: 0.4100\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.48000\n",
            "Epoch 24/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 1.1035 - acc: 0.6089 - val_loss: 1.4047 - val_acc: 0.5600\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.48000 to 0.56000, saving model to /content/gdrive/My Drive/CNNModel1.h5\n",
            "Epoch 25/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 1.0051 - acc: 0.6367 - val_loss: 1.4387 - val_acc: 0.4700\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.56000\n",
            "Epoch 26/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.8519 - acc: 0.7256 - val_loss: 2.4139 - val_acc: 0.4400\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.56000\n",
            "Epoch 27/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.8264 - acc: 0.7344 - val_loss: 2.2641 - val_acc: 0.4500\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.56000\n",
            "Epoch 28/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.8013 - acc: 0.7467 - val_loss: 1.5754 - val_acc: 0.5300\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.56000\n",
            "Epoch 29/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.6661 - acc: 0.7844 - val_loss: 1.5225 - val_acc: 0.5100\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.56000\n",
            "Epoch 30/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.4828 - acc: 0.8344 - val_loss: 2.5568 - val_acc: 0.5500\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.56000\n",
            "Epoch 31/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.4989 - acc: 0.8456 - val_loss: 2.4455 - val_acc: 0.5500\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.56000\n",
            "Epoch 32/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.4417 - acc: 0.8800 - val_loss: 3.3231 - val_acc: 0.5200\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.56000\n",
            "Epoch 33/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.3635 - acc: 0.8911 - val_loss: 1.9484 - val_acc: 0.6200\n",
            "\n",
            "Epoch 00033: val_acc improved from 0.56000 to 0.62000, saving model to /content/gdrive/My Drive/CNNModel1.h5\n",
            "Epoch 34/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.3734 - acc: 0.8744 - val_loss: 2.3048 - val_acc: 0.5600\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.62000\n",
            "Epoch 35/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.3082 - acc: 0.9144 - val_loss: 2.3867 - val_acc: 0.5400\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.62000\n",
            "Epoch 36/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.2408 - acc: 0.9322 - val_loss: 2.5827 - val_acc: 0.5900\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.62000\n",
            "Epoch 37/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.2893 - acc: 0.9211 - val_loss: 1.8245 - val_acc: 0.5700\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.62000\n",
            "Epoch 38/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.1934 - acc: 0.9511 - val_loss: 1.7120 - val_acc: 0.6300\n",
            "\n",
            "Epoch 00038: val_acc improved from 0.62000 to 0.63000, saving model to /content/gdrive/My Drive/CNNModel1.h5\n",
            "Epoch 39/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.1422 - acc: 0.9578 - val_loss: 2.4965 - val_acc: 0.5600\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.63000\n",
            "Epoch 40/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.2286 - acc: 0.9456 - val_loss: 2.3373 - val_acc: 0.6100\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.63000\n",
            "Epoch 41/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0669 - acc: 0.9767 - val_loss: 2.7375 - val_acc: 0.5600\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.63000\n",
            "Epoch 42/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.2183 - acc: 0.9456 - val_loss: 1.8598 - val_acc: 0.6400\n",
            "\n",
            "Epoch 00042: val_acc improved from 0.63000 to 0.64000, saving model to /content/gdrive/My Drive/CNNModel1.h5\n",
            "Epoch 43/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0901 - acc: 0.9722 - val_loss: 2.3805 - val_acc: 0.5900\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.64000\n",
            "Epoch 44/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.1071 - acc: 0.9722 - val_loss: 2.6832 - val_acc: 0.6300\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.64000\n",
            "Epoch 45/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.1511 - acc: 0.9589 - val_loss: 4.0999 - val_acc: 0.4600\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.64000\n",
            "Epoch 46/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0822 - acc: 0.9756 - val_loss: 3.5796 - val_acc: 0.5600\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.64000\n",
            "Epoch 47/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.1361 - acc: 0.9689 - val_loss: 3.1232 - val_acc: 0.6200\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.64000\n",
            "Epoch 48/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.1145 - acc: 0.9744 - val_loss: 2.5598 - val_acc: 0.5600\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.64000\n",
            "Epoch 49/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0637 - acc: 0.9844 - val_loss: 3.1378 - val_acc: 0.6200\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.64000\n",
            "Epoch 50/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.1732 - acc: 0.9667 - val_loss: 3.2972 - val_acc: 0.5300\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.64000\n",
            "Epoch 51/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0152 - acc: 0.9956 - val_loss: 3.7065 - val_acc: 0.6000\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.64000\n",
            "Epoch 52/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.2211 - acc: 0.9622 - val_loss: 2.4568 - val_acc: 0.6200\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.64000\n",
            "Epoch 53/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0179 - acc: 0.9933 - val_loss: 2.9658 - val_acc: 0.6100\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.64000\n",
            "Epoch 54/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.1729 - acc: 0.9744 - val_loss: 4.5086 - val_acc: 0.4700\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.64000\n",
            "Epoch 55/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.1067 - acc: 0.9756 - val_loss: 2.8546 - val_acc: 0.6500\n",
            "\n",
            "Epoch 00055: val_acc improved from 0.64000 to 0.65000, saving model to /content/gdrive/My Drive/CNNModel1.h5\n",
            "Epoch 56/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0096 - acc: 0.9989 - val_loss: 3.9884 - val_acc: 0.4700\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.65000\n",
            "Epoch 57/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.1079 - acc: 0.9733 - val_loss: 3.0449 - val_acc: 0.6200\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.65000\n",
            "Epoch 58/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0962 - acc: 0.9689 - val_loss: 2.9864 - val_acc: 0.5500\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.65000\n",
            "Epoch 59/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.1123 - acc: 0.9767 - val_loss: 2.8638 - val_acc: 0.6100\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.65000\n",
            "Epoch 60/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.1999 - acc: 0.9578 - val_loss: 2.6357 - val_acc: 0.5700\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.65000\n",
            "Epoch 61/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0257 - acc: 0.9944 - val_loss: 2.9507 - val_acc: 0.6200\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.65000\n",
            "Epoch 62/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0410 - acc: 0.9900 - val_loss: 4.4199 - val_acc: 0.5300\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.65000\n",
            "Epoch 63/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.1737 - acc: 0.9611 - val_loss: 3.4155 - val_acc: 0.6000\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.65000\n",
            "Epoch 64/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0063 - acc: 0.9967 - val_loss: 3.6698 - val_acc: 0.6000\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.65000\n",
            "Epoch 65/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.1775 - acc: 0.9656 - val_loss: 3.4533 - val_acc: 0.6000\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.65000\n",
            "Epoch 66/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0739 - acc: 0.9867 - val_loss: 3.3867 - val_acc: 0.6000\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.65000\n",
            "Epoch 67/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.1733 - acc: 0.9756 - val_loss: 4.2640 - val_acc: 0.5800\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.65000\n",
            "Epoch 68/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.1788 - acc: 0.9733 - val_loss: 3.1124 - val_acc: 0.6500\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.65000\n",
            "Epoch 69/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0151 - acc: 0.9944 - val_loss: 4.7093 - val_acc: 0.5100\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.65000\n",
            "Epoch 70/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.1665 - acc: 0.9800 - val_loss: 3.9229 - val_acc: 0.6600\n",
            "\n",
            "Epoch 00070: val_acc improved from 0.65000 to 0.66000, saving model to /content/gdrive/My Drive/CNNModel1.h5\n",
            "Epoch 71/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.1016 - acc: 0.9800 - val_loss: 3.4555 - val_acc: 0.5600\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.66000\n",
            "Epoch 72/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0536 - acc: 0.9833 - val_loss: 3.0187 - val_acc: 0.5600\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.66000\n",
            "Epoch 73/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0890 - acc: 0.9778 - val_loss: 3.9511 - val_acc: 0.5800\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.66000\n",
            "Epoch 74/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0195 - acc: 0.9933 - val_loss: 3.2847 - val_acc: 0.5800\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.66000\n",
            "Epoch 75/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0057 - acc: 0.9967 - val_loss: 4.3420 - val_acc: 0.5800\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.66000\n",
            "Epoch 76/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.2290 - acc: 0.9644 - val_loss: 4.1251 - val_acc: 0.5100\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.66000\n",
            "Epoch 77/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0475 - acc: 0.9878 - val_loss: 3.4928 - val_acc: 0.6000\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.66000\n",
            "Epoch 78/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0153 - acc: 0.9933 - val_loss: 4.5731 - val_acc: 0.5500\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.66000\n",
            "Epoch 79/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.1680 - acc: 0.9700 - val_loss: 3.6464 - val_acc: 0.5700\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.66000\n",
            "Epoch 80/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0095 - acc: 0.9967 - val_loss: 3.4520 - val_acc: 0.6200\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.66000\n",
            "Epoch 81/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0093 - acc: 0.9967 - val_loss: 3.9618 - val_acc: 0.6000\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.66000\n",
            "Epoch 82/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.1354 - acc: 0.9789 - val_loss: 4.0146 - val_acc: 0.5700\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.66000\n",
            "Epoch 83/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.2053 - acc: 0.9689 - val_loss: 3.6871 - val_acc: 0.5800\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.66000\n",
            "Epoch 84/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.1354 - acc: 0.9833 - val_loss: 3.9658 - val_acc: 0.5700\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.66000\n",
            "Epoch 85/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0695 - acc: 0.9867 - val_loss: 3.9177 - val_acc: 0.5400\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.66000\n",
            "Epoch 86/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.1116 - acc: 0.9811 - val_loss: 3.6763 - val_acc: 0.5000\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.66000\n",
            "Epoch 87/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0687 - acc: 0.9800 - val_loss: 2.6715 - val_acc: 0.6500\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.66000\n",
            "Epoch 88/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0047 - acc: 0.9989 - val_loss: 3.1250 - val_acc: 0.6400\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.66000\n",
            "Epoch 89/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0745 - acc: 0.9833 - val_loss: 3.8367 - val_acc: 0.6000\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.66000\n",
            "Epoch 90/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0138 - acc: 0.9956 - val_loss: 3.2861 - val_acc: 0.6600\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.66000\n",
            "Epoch 91/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.1168 - acc: 0.9789 - val_loss: 4.0601 - val_acc: 0.6200\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.66000\n",
            "Epoch 92/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.1534 - acc: 0.9789 - val_loss: 4.3005 - val_acc: 0.5900\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.66000\n",
            "Epoch 93/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0066 - acc: 0.9978 - val_loss: 3.8934 - val_acc: 0.6700\n",
            "\n",
            "Epoch 00093: val_acc improved from 0.66000 to 0.67000, saving model to /content/gdrive/My Drive/CNNModel1.h5\n",
            "Epoch 94/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0045 - acc: 0.9989 - val_loss: 3.6998 - val_acc: 0.6400\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.67000\n",
            "Epoch 95/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.1914 - acc: 0.9756 - val_loss: 3.9669 - val_acc: 0.6100\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.67000\n",
            "Epoch 96/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0815 - acc: 0.9856 - val_loss: 5.7561 - val_acc: 0.5100\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.67000\n",
            "Epoch 97/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0391 - acc: 0.9933 - val_loss: 4.1302 - val_acc: 0.5600\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.67000\n",
            "Epoch 98/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0799 - acc: 0.9889 - val_loss: 3.8092 - val_acc: 0.6300\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.67000\n",
            "Epoch 99/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.1459 - acc: 0.9789 - val_loss: 4.5304 - val_acc: 0.5600\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.67000\n",
            "Epoch 100/100\n",
            "900/900 [==============================] - 9s 10ms/step - loss: 0.0474 - acc: 0.9922 - val_loss: 4.7580 - val_acc: 0.5600\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.67000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kLUlPIbmuyR4",
        "outputId": "cfbb0f0d-ad8e-4b2c-9ecc-4ff889411f33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train','Val'],loc = 'upper right')\n",
        "plt.show()\n",
        "#model.fit(X,Y1,batch_size =32 ,epochs=50,verbose=1,validation_data=(X2,Y3),callbacks=[checkpointer])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn5ZPYM7s227",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jaqzUZd8y56J",
        "outputId": "06956d72-0431-44a3-ac9a-cb6620825bb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('/content/gdrive/My Drive/CNNModel1.h5')\n",
        "prediction = model.predict_classes(X2)\n",
        "print(prediction.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rBVH40M7AWS6",
        "outputId": "82d9df3d-57b5-4f67-b1de-1d096be556e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "test_eval = model.evaluate(X2, Y3, verbose=0)\n",
        "print('Test loss:', test_eval[0])\n",
        "print('Test accuracy:', test_eval[1])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 3.893381175994873\n",
            "Test accuracy: 0.67\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TP1bmuAhA-fD",
        "outputId": "37b77e9e-8437-40e1-c948-41e4240dd3a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "\"\"\"\n",
        "from sklearn.metrics import confusion_matrix \n",
        "results = confusion_matrix(Y2, prediction) \n",
        "print(results)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "target_names = [\"Class {}\".format(i) for i in range(len(categories))]\n",
        "print(classification_report(Y2, prediction, target_names=target_names))\n",
        "\"\"\"\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(Y2, prediction)\n",
        "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "cm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7, 0. , 0. , 0.3, 0. , 0. , 0. , 0. , 0. , 0. ],\n",
              "       [0. , 0.7, 0. , 0. , 0. , 0.1, 0. , 0.1, 0.1, 0. ],\n",
              "       [0. , 0. , 0.8, 0. , 0. , 0. , 0. , 0.1, 0.1, 0. ],\n",
              "       [0.1, 0. , 0. , 0.5, 0. , 0.2, 0. , 0.1, 0.1, 0. ],\n",
              "       [0. , 0. , 0. , 0. , 0.8, 0. , 0.1, 0.1, 0. , 0. ],\n",
              "       [0. , 0.1, 0. , 0.1, 0. , 0.8, 0. , 0. , 0. , 0. ],\n",
              "       [0. , 0. , 0. , 0. , 0.1, 0. , 0.8, 0. , 0. , 0.1],\n",
              "       [0. , 0. , 0. , 0.3, 0.2, 0. , 0.1, 0.4, 0. , 0. ],\n",
              "       [0. , 0.2, 0. , 0.2, 0.1, 0. , 0. , 0. , 0.5, 0. ],\n",
              "       [0. , 0.2, 0. , 0. , 0. , 0.1, 0. , 0. , 0. , 0.7]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbeLTEI_1UYH",
        "colab_type": "code",
        "outputId": "3f6cfd03-8eda-45fb-cd14-39392ce2d8e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        }
      },
      "source": [
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df_cm = pd.DataFrame(cm, index = [i for i in ['blues','classical','country','disco','hiphop','jazz','metal','pop','reggae','rock']],\n",
        "                  columns = [i for i in ['blues','classical','country','disco','hiphop','jazz','metal','pop','reggae','rock']])\n",
        "plt.figure(figsize = (20,10))\n",
        "\n",
        "hm = sn.heatmap(df_cm, annot=True, linewidths=1)\n",
        "\n",
        "figure = hm.get_figure()    \n",
        "hm.set_ylim(len(df_cm)-1, -0.5)\n",
        "plt.show()\n",
        "figure.savefig('cm3.png',dpi=300,transparent=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABAwAAAJPCAYAAAD4/0aOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1440x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "snlz2X4OBOFr",
        "colab": {}
      },
      "source": [
        "np.save(\"/content/gdrive/My Drive/Training_features.npy\",X)\n",
        "np.save(\"/content/gdrive/My Drive/Training_class_labels.npy\",Y)\n",
        "np.save(\"/content/gdrive/My Drive/Test_features\",X2)\n",
        "np.save(\"/content/gdrive/My Drive/Test_class_labels\",Y2)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wGN0ZuTpChjy",
        "colab": {}
      },
      "source": [
        "########################RUN FROM THIS CELL\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential,Model\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, LSTM,Conv2D, Dropout,Input, Flatten,Activation,MaxPooling2D,AveragePooling2D,BatchNormalization,Conv3D,Conv1D\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import optimizers\n",
        "#CNNLSTM\n",
        "\n",
        "X = np.load(\"/content/gdrive/My Drive/Training_features.npy\")\n",
        "Y= np.load(\"/content/gdrive/My Drive/Training_class_labels.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yCChwabKEof5",
        "colab": {}
      },
      "source": [
        "X2 = np.load(\"/content/gdrive/My Drive/Test_features.npy\")\n",
        "Y2 = np.load(\"/content/gdrive/My Drive/Test_class_labels.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Uv1HXcovA-sE",
        "colab": {}
      },
      "source": [
        "Y1 = to_categorical(Y)\n",
        "Y3 = to_categorical(Y2)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "566YaNmJFv7U",
        "outputId": "88489efd-6a72-4821-b4c9-e7ec6f1e4325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "Inp = Input(shape = (480,640,3))\n",
        "\n",
        "model = ((Conv2D(32,(3,3),padding='same',activation='relu')))(Inp)\n",
        "#model.add(TimeDistributed(base_model,input_shape=base_model.input_shape))\n",
        "model = ((Conv2D(32,(3,3),activation='relu')))(model)\n",
        "model = ((AveragePooling2D(pool_size = (2,2))))(model)\n",
        "model = (Dropout(0.25))(model)\n",
        "\n",
        "model = ((Conv2D(64,(4,4),padding='same',activation='relu')))(model)\n",
        "model = ((Conv2D(64,(4,4),activation='relu')))(model)\n",
        "model = ((AveragePooling2D(pool_size = (2,2))))(model)\n",
        "model = (Dropout(0.25))(model)\n",
        "\n",
        "model = ((Conv2D(64,(4,4),padding='same',activation='relu')))(model)\n",
        "model = ((Conv2D(64,(4,4),activation='relu')))(model)\n",
        "model = ((AveragePooling2D(pool_size = (2,2))))(model)\n",
        "model  = (Dropout(0.25))(model)\n",
        "#model.add(Conv2D(64,(10,10),padding='same',activation='relu',strides=(2,2)))\n",
        "#model.add(Conv2D(64,(10,10),activation='relu',strides=(2,2)))\n",
        "#model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "#LSTM\n",
        "\n",
        "\n",
        "#\n",
        "\"\"\"\n",
        "lstm1,h,c = LSTM(96, return_sequences=True,return_state=True)([lstm1,h,c])\n",
        "lstm1,h,c = LSTM(96, return_sequences=False,return_state=True)([lstm1,h,c])\n",
        "#y = Lambda(lambda x: tf.keras.backend.concatenate([h,c],0))([lstm1,h,c])\n",
        "y = Concatenate()([h,c])\n",
        "model_language = Model(inputs=inputs1, outputs=y)\n",
        "# combined model\n",
        "conc = keras.layers.Multiply()([model_language.output,model.output])\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "model = (TimeDistributed(Flatten()))(model)\n",
        "model = (LSTM(1000,stateful=False,return_sequences=True,activation='relu'))(model)\n",
        "#model = (Dropout(0.3))(model)\n",
        "model = (LSTM(500,stateful=False))(model)\n",
        "#model = (LSTM(200,stateful=False))(model)\n",
        "#model = (LSTM(50,stateful=False))(model)\n",
        "#model = (Dropout(0.3))(model)\n",
        "\n",
        "model = (Dense(100,activation='relu'))(model)\n",
        "model = (Dropout(0.3))(model)\n",
        "model = (Dense(50,activation='relu'))(model)\n",
        "model = (Dropout(0.3))(model)\n",
        "#model.add(Dense(64,activation='relu'))\n",
        "\n",
        "model = (Dense(10,activation='softmax'))(model)\n",
        "#model.build((32,480,640,3))\n",
        "#model.build(('None',480,640,3))\n",
        "\n",
        "model_cnn = Model(Inp, model )\n",
        "\n",
        "model_cnn.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 480, 640, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_73 (Conv2D)           (None, 480, 640, 32)      896       \n",
            "_________________________________________________________________\n",
            "conv2d_74 (Conv2D)           (None, 478, 638, 32)      9248      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_37 (Averag (None, 239, 319, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         (None, 239, 319, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_75 (Conv2D)           (None, 239, 319, 64)      32832     \n",
            "_________________________________________________________________\n",
            "conv2d_76 (Conv2D)           (None, 236, 316, 64)      65600     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_38 (Averag (None, 118, 158, 64)      0         \n",
            "_________________________________________________________________\n",
            "dropout_40 (Dropout)         (None, 118, 158, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_77 (Conv2D)           (None, 118, 158, 64)      65600     \n",
            "_________________________________________________________________\n",
            "conv2d_78 (Conv2D)           (None, 115, 155, 64)      65600     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_39 (Averag (None, 57, 77, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_41 (Dropout)         (None, 57, 77, 64)        0         \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 57, 4928)          0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 57, 1000)          23716000  \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 500)               3002000   \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 100)               50100     \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dropout_43 (Dropout)         (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 27,013,436\n",
            "Trainable params: 27,013,436\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "11Y4vZKLFEPD",
        "outputId": "078fc973-60f4-4211-d901-f9389914eb17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#model1 = trainCNNLSTM1()\n",
        "sgd = optimizers.SGD(lr=1, momentum=0.9, nesterov=True)\n",
        "model_cnn.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "checkpointer = ModelCheckpoint(filepath='/content/gdrive/My Drive/CNNLSTMModelNew.h5',monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "history1 = model_cnn.fit(X,Y1,batch_size =32 ,epochs=100,verbose=1,validation_data=(X2,Y3),callbacks=[checkpointer])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 900 samples, validate on 100 samples\n",
            "Epoch 1/100\n",
            "900/900 [==============================] - 29s 32ms/step - loss: 2.3813 - acc: 0.0911 - val_loss: 2.4468 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.10000, saving model to /content/gdrive/My Drive/CNNLSTMModelNew.h5\n",
            "Epoch 2/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3892 - acc: 0.0811 - val_loss: 2.3763 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.10000\n",
            "Epoch 3/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3666 - acc: 0.0822 - val_loss: 2.3328 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.10000\n",
            "Epoch 4/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3619 - acc: 0.0978 - val_loss: 2.3736 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.10000\n",
            "Epoch 5/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3776 - acc: 0.0811 - val_loss: 2.3455 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.10000\n",
            "Epoch 6/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3513 - acc: 0.1056 - val_loss: 2.3816 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.10000\n",
            "Epoch 7/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3506 - acc: 0.0944 - val_loss: 2.4373 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.10000\n",
            "Epoch 8/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3560 - acc: 0.0900 - val_loss: 2.3770 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.10000\n",
            "Epoch 9/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3755 - acc: 0.0900 - val_loss: 2.4104 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.10000\n",
            "Epoch 10/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3711 - acc: 0.0833 - val_loss: 2.3781 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.10000\n",
            "Epoch 11/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3635 - acc: 0.0856 - val_loss: 2.3908 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.10000\n",
            "Epoch 12/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3651 - acc: 0.1022 - val_loss: 2.3637 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.10000\n",
            "Epoch 13/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3598 - acc: 0.1067 - val_loss: 2.3967 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.10000\n",
            "Epoch 14/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3615 - acc: 0.1022 - val_loss: 2.4653 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.10000\n",
            "Epoch 15/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3765 - acc: 0.0900 - val_loss: 2.3612 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.10000\n",
            "Epoch 16/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3493 - acc: 0.0956 - val_loss: 2.3579 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.10000\n",
            "Epoch 17/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3573 - acc: 0.0878 - val_loss: 2.3665 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.10000\n",
            "Epoch 18/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3644 - acc: 0.0956 - val_loss: 2.3718 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.10000\n",
            "Epoch 19/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3518 - acc: 0.0922 - val_loss: 2.3770 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.10000\n",
            "Epoch 20/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3554 - acc: 0.1056 - val_loss: 2.3776 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.10000\n",
            "Epoch 21/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3639 - acc: 0.0844 - val_loss: 2.3885 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.10000\n",
            "Epoch 22/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3698 - acc: 0.0878 - val_loss: 2.3338 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.10000\n",
            "Epoch 23/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3714 - acc: 0.0689 - val_loss: 2.3594 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.10000\n",
            "Epoch 24/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3588 - acc: 0.0933 - val_loss: 2.4164 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.10000\n",
            "Epoch 25/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3747 - acc: 0.0967 - val_loss: 2.4339 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.10000\n",
            "Epoch 26/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3692 - acc: 0.0911 - val_loss: 2.3491 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.10000\n",
            "Epoch 27/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3559 - acc: 0.1044 - val_loss: 2.3717 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.10000\n",
            "Epoch 28/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3671 - acc: 0.0833 - val_loss: 2.3699 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.10000\n",
            "Epoch 29/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3795 - acc: 0.0978 - val_loss: 2.3756 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.10000\n",
            "Epoch 30/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3595 - acc: 0.0933 - val_loss: 2.4202 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.10000\n",
            "Epoch 31/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3718 - acc: 0.0867 - val_loss: 2.3661 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.10000\n",
            "Epoch 32/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3642 - acc: 0.0811 - val_loss: 2.4022 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.10000\n",
            "Epoch 33/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3581 - acc: 0.1022 - val_loss: 2.3836 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.10000\n",
            "Epoch 34/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3608 - acc: 0.0944 - val_loss: 2.3539 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.10000\n",
            "Epoch 35/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3604 - acc: 0.0878 - val_loss: 2.3271 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.10000\n",
            "Epoch 36/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3681 - acc: 0.0867 - val_loss: 2.3454 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.10000\n",
            "Epoch 37/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3467 - acc: 0.0967 - val_loss: 2.3395 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.10000\n",
            "Epoch 38/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3519 - acc: 0.0844 - val_loss: 2.3493 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.10000\n",
            "Epoch 39/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3649 - acc: 0.0989 - val_loss: 2.3758 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.10000\n",
            "Epoch 40/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3472 - acc: 0.1056 - val_loss: 2.3496 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.10000\n",
            "Epoch 41/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3638 - acc: 0.0956 - val_loss: 2.3522 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.10000\n",
            "Epoch 42/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3581 - acc: 0.0867 - val_loss: 2.3246 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.10000\n",
            "Epoch 43/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3576 - acc: 0.0933 - val_loss: 2.4239 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.10000\n",
            "Epoch 44/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3684 - acc: 0.0922 - val_loss: 2.4060 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.10000\n",
            "Epoch 45/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3660 - acc: 0.1022 - val_loss: 2.4092 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.10000\n",
            "Epoch 46/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3676 - acc: 0.1111 - val_loss: 2.3703 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.10000\n",
            "Epoch 47/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3539 - acc: 0.0978 - val_loss: 2.3858 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.10000\n",
            "Epoch 48/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3672 - acc: 0.0744 - val_loss: 2.3313 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.10000\n",
            "Epoch 49/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3475 - acc: 0.0978 - val_loss: 2.3658 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.10000\n",
            "Epoch 50/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3585 - acc: 0.1089 - val_loss: 2.3516 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.10000\n",
            "Epoch 51/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3675 - acc: 0.0733 - val_loss: 2.3491 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.10000\n",
            "Epoch 52/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3582 - acc: 0.0756 - val_loss: 2.3794 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.10000\n",
            "Epoch 53/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3625 - acc: 0.0922 - val_loss: 2.3631 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.10000\n",
            "Epoch 54/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3761 - acc: 0.0856 - val_loss: 2.3982 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.10000\n",
            "Epoch 55/100\n",
            "900/900 [==============================] - 22s 24ms/step - loss: 2.3581 - acc: 0.1022 - val_loss: 2.4096 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.10000\n",
            "Epoch 56/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3581 - acc: 0.0789 - val_loss: 2.3234 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.10000\n",
            "Epoch 57/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3488 - acc: 0.1033 - val_loss: 2.3692 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.10000\n",
            "Epoch 58/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3605 - acc: 0.1033 - val_loss: 2.3913 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.10000\n",
            "Epoch 59/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3839 - acc: 0.0822 - val_loss: 2.4050 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.10000\n",
            "Epoch 60/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3630 - acc: 0.0989 - val_loss: 2.4939 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.10000\n",
            "Epoch 61/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3897 - acc: 0.0956 - val_loss: 2.3574 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.10000\n",
            "Epoch 62/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3583 - acc: 0.0844 - val_loss: 2.4041 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.10000\n",
            "Epoch 63/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3737 - acc: 0.0844 - val_loss: 2.3896 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.10000\n",
            "Epoch 64/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3553 - acc: 0.0889 - val_loss: 2.3655 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.10000\n",
            "Epoch 65/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3551 - acc: 0.0900 - val_loss: 2.3604 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.10000\n",
            "Epoch 66/100\n",
            "900/900 [==============================] - 22s 24ms/step - loss: 2.3494 - acc: 0.1078 - val_loss: 2.3904 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.10000\n",
            "Epoch 67/100\n",
            "900/900 [==============================] - 22s 24ms/step - loss: 2.3633 - acc: 0.0878 - val_loss: 2.3745 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.10000\n",
            "Epoch 68/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3600 - acc: 0.1000 - val_loss: 2.4343 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.10000\n",
            "Epoch 69/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3701 - acc: 0.0956 - val_loss: 2.3521 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.10000\n",
            "Epoch 70/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3658 - acc: 0.0978 - val_loss: 2.5056 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.10000\n",
            "Epoch 71/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3945 - acc: 0.0989 - val_loss: 2.3315 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.10000\n",
            "Epoch 72/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3517 - acc: 0.1067 - val_loss: 2.3433 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.10000\n",
            "Epoch 73/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3656 - acc: 0.0822 - val_loss: 2.3314 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.10000\n",
            "Epoch 74/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3844 - acc: 0.1011 - val_loss: 2.3783 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.10000\n",
            "Epoch 75/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3437 - acc: 0.1122 - val_loss: 2.3894 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.10000\n",
            "Epoch 76/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3608 - acc: 0.0933 - val_loss: 2.4372 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.10000\n",
            "Epoch 77/100\n",
            "900/900 [==============================] - 22s 24ms/step - loss: 2.3804 - acc: 0.0844 - val_loss: 2.3255 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.10000\n",
            "Epoch 78/100\n",
            "900/900 [==============================] - 22s 24ms/step - loss: 2.3591 - acc: 0.0944 - val_loss: 2.3525 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.10000\n",
            "Epoch 79/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3648 - acc: 0.0933 - val_loss: 2.4437 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.10000\n",
            "Epoch 80/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3691 - acc: 0.1011 - val_loss: 2.4254 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.10000\n",
            "Epoch 81/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3645 - acc: 0.0778 - val_loss: 2.3701 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.10000\n",
            "Epoch 82/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3587 - acc: 0.0989 - val_loss: 2.4100 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.10000\n",
            "Epoch 83/100\n",
            "900/900 [==============================] - 22s 24ms/step - loss: 2.3551 - acc: 0.0800 - val_loss: 2.4366 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.10000\n",
            "Epoch 84/100\n",
            "900/900 [==============================] - 22s 24ms/step - loss: 2.3610 - acc: 0.1011 - val_loss: 2.4703 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.10000\n",
            "Epoch 85/100\n",
            "900/900 [==============================] - 22s 24ms/step - loss: 2.3737 - acc: 0.0922 - val_loss: 2.3860 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.10000\n",
            "Epoch 86/100\n",
            "900/900 [==============================] - 22s 24ms/step - loss: 2.3634 - acc: 0.1000 - val_loss: 2.3589 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.10000\n",
            "Epoch 87/100\n",
            "900/900 [==============================] - 22s 24ms/step - loss: 2.3581 - acc: 0.0967 - val_loss: 2.4339 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.10000\n",
            "Epoch 88/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3754 - acc: 0.0922 - val_loss: 2.3480 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.10000\n",
            "Epoch 89/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3586 - acc: 0.1044 - val_loss: 2.3905 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.10000\n",
            "Epoch 90/100\n",
            "900/900 [==============================] - 22s 24ms/step - loss: 2.3598 - acc: 0.1100 - val_loss: 2.4057 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.10000\n",
            "Epoch 91/100\n",
            "900/900 [==============================] - 22s 24ms/step - loss: 2.3458 - acc: 0.1056 - val_loss: 2.4197 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.10000\n",
            "Epoch 92/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3629 - acc: 0.0944 - val_loss: 2.3733 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.10000\n",
            "Epoch 93/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3712 - acc: 0.0911 - val_loss: 2.4148 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.10000\n",
            "Epoch 94/100\n",
            "900/900 [==============================] - 22s 24ms/step - loss: 2.3566 - acc: 0.1033 - val_loss: 2.3402 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.10000\n",
            "Epoch 95/100\n",
            "900/900 [==============================] - 22s 24ms/step - loss: 2.3565 - acc: 0.0989 - val_loss: 2.4322 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.10000\n",
            "Epoch 96/100\n",
            "900/900 [==============================] - 22s 24ms/step - loss: 2.3677 - acc: 0.1011 - val_loss: 2.4310 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.10000\n",
            "Epoch 97/100\n",
            "900/900 [==============================] - 22s 24ms/step - loss: 2.3563 - acc: 0.1000 - val_loss: 2.4167 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.10000\n",
            "Epoch 98/100\n",
            "900/900 [==============================] - 22s 24ms/step - loss: 2.3644 - acc: 0.0856 - val_loss: 2.3736 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.10000\n",
            "Epoch 99/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3629 - acc: 0.0933 - val_loss: 2.3562 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.10000\n",
            "Epoch 100/100\n",
            "900/900 [==============================] - 22s 25ms/step - loss: 2.3702 - acc: 0.0889 - val_loss: 2.3285 - val_acc: 0.1000\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FhKZUvTDFRGz",
        "colab": {}
      },
      "source": [
        "model_cnn.fit(X,Y1,batch_size =32 ,epochs=100,verbose=1,validation_data=(X2,Y3),callbacks=[checkpointer])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeJC80X7fIhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cnn.fit(X,Y1,batch_size =32 ,epochs=100,verbose=1,validation_data=(X2,Y3),callbacks=[checkpointer])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD81CzRYnT-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cnn.fit(X,Y1,batch_size =32 ,epochs=100,verbose=1,validation_data=(X2,Y3),callbacks=[checkpointer])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MHuVWyJa_b-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}